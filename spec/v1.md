# Zerverless Platform

## Specification Document for AI-Assisted Development

**Version:** 0.2.0-alpha  
**Last Updated:** 2024-12  
**Purpose:** Spec-driven development with AI IDEs (Cursor, Copilot, etc.)

---

## Table of Contents

1. [Project Vision](#1-project-vision)
2. [Tech Stack](#2-tech-stack)
3. [Architecture Overview](#3-architecture-overview)
4. [Project Structure](#4-project-structure)
5. [Data Models](#5-data-models)
6. [API Contracts](#6-api-contracts) *(see [contracts.md](contracts.md))*
7. [Docker Development Setup](#7-docker-development-setup)
8. [Configuration](#8-configuration)
9. [Development Phases](#9-development-phases)
10. [Testing Strategy](#10-testing-strategy)
11. [Future Considerations](#11-future-considerations)

---

## 1. Project Vision

### 1.1 What We're Building

A **non-profit, volunteer-powered distributed compute platform** — like torrents, but for computation. Volunteers donate CPU cycles via browser or native client; developers submit jobs (Wasm modules) that execute on the volunteer network.

### 1.2 Core Principles

- **Non-profit**: Community-owned, no crypto/tokens, donation-based
- **Easy volunteering**: Open browser tab → donate cycles (zero install)
- **Decentralized**: No single point of failure, DHT-based coordination
- **Secure**: Wasm sandboxing for untrusted code execution
- **Federated**: Multiple organizations can run nodes and mesh together

### 1.3 Key Actors

|Actor|Description|
|---|---|
|**Volunteer**|Donates compute via browser or native client|
|**Orchestrator**|Node that coordinates jobs and volunteers|
|**Developer**|Submits Wasm jobs to the network|
|**Admin**|Runs orchestrator infrastructure|

### 1.4 Job Flow

```
Developer submits job → Orchestrator receives → Routes to Volunteer → Executes Wasm → Returns result
```

---

## 2. Tech Stack

### 2.1 Core Technologies

|Component|Technology|Rationale|
|---|---|---|
|**Language**|Go 1.22+|Single binary, excellent concurrency, native IPFS support|
|**IPFS/P2P**|Boxo + libp2p|Battle-tested IPFS components, native DHT, peer discovery|
|**Wasm Runtime**|wazero|Pure Go, no CGO, secure sandbox|
|**HTTP Router**|chi|Lightweight, idiomatic, middleware support|
|**WebSockets**|nhooyr/websocket|Modern, context-aware, net/http compatible|
|**Storage**|Boxo blockstore|Content-addressed storage via IPFS|
|**DHT**|libp2p Kademlia|Peer discovery and routing (via Boxo)|
|**Containerization**|Docker + Docker Compose|Development and deployment|

### 2.2 Go Dependencies

```go
// go.mod
module github.com/zerverless/orchestrator

go 1.22

require (
    github.com/ipfs/boxo v0.24.0
    github.com/libp2p/go-libp2p v0.36.0
    github.com/tetratelabs/wazero v1.8.0
    github.com/go-chi/chi/v5 v5.1.0
    nhooyr.io/websocket v1.8.11
)
```

### 2.3 Why Go + Boxo?

|Benefit|Description|
|---|---|
|**Native IPFS**|Boxo provides first-class IPFS components, not HTTP wrappers|
|**DHT Built-in**|libp2p Kademlia handles peer discovery out of the box|
|**Single Binary**|Easy deployment, no runtime dependencies|
|**Concurrency**|Goroutines handle thousands of volunteers efficiently|
|**Wazero**|Pure Go Wasm runtime with no CGO, excellent sandbox|
|**Battle-tested**|Boxo powers Kubo (reference IPFS implementation)|

---

## 3. Architecture Overview

### 3.1 High-Level Architecture

```
┌─────────────────────────────────────────────────────────────────────┐
│                         Internet                                    │
└─────────────────────────────────────────────────────────────────────┘
                                │
        ┌───────────────────────┼───────────────────────┐
        │                       │                       │
        ▼                       ▼                       ▼
┌───────────────┐       ┌───────────────┐       ┌───────────────┐
│ Orchestrator A│◄─────►│ Orchestrator B│◄─────►│ Orchestrator C│
│               │libp2p │               │libp2p │               │
│  ┌─────────┐  │       │  ┌─────────┐  │       │  ┌─────────┐  │
│  │WebSocket│  │       │  │WebSocket│  │       │  │WebSocket│  │
│  │ Server  │  │       │  │ Server  │  │       │  │ Server  │  │
│  └────┬────┘  │       │  └────┬────┘  │       │  └────┬────┘  │
│       │       │       │       │       │       │       │       │
└───────┼───────┘       └───────┼───────┘       └───────┼───────┘
        │                       │                       │
   ┌────┴────┐             ┌────┴────┐             ┌────┴────┐
   │Volunteers│             │Volunteers│             │Volunteers│
   │(Browser) │             │(Browser) │             │(Browser) │
   └──────────┘             └──────────┘             └──────────┘

┌─────────────────────────────────────────────────────────────────────┐
│                    IPFS Network (via Boxo)                          │
│                   (Wasm storage, results)                           │
└─────────────────────────────────────────────────────────────────────┘
```

### 3.2 Component Responsibilities

|Component|Responsibilities|Go Package|
|---|---|---|
|**Orchestrator**|Accept jobs, manage volunteers, route to peers|`cmd/orchestrator`|
|**Volunteer Manager**|Track connected volunteers, health checks|`internal/volunteer`|
|**Job Queue**|FIFO queue, job assignment, result collection|`internal/job`|
|**Peer Manager**|libp2p connections, DHT participation|`internal/peer`|
|**IPFS Node**|Store/retrieve Wasm and results|`internal/ipfs` (Boxo)|
|**HTTP API**|Job submission, status queries|`internal/api`|
|**WebSocket Server**|Volunteer connections, real-time dispatch|`internal/ws`|

### 3.3 Boxo Components Used

|Boxo Package|Purpose|
|---|---|
|`boxo/blockstore`|Content-addressed block storage|
|`boxo/blockservice`|Block retrieval with exchange|
|`boxo/gateway`|IPFS gateway for volunteers|
|`boxo/routing`|Content and peer routing|
|`boxo/ipld`|Data structure handling|
|`boxo/files`|File abstraction layer|

### 3.4 Data Flow

```
1. Developer POSTs job to /api/jobs
2. Orchestrator stores Wasm in Boxo blockstore (if not already)
3. Job enters pending queue
4. Available volunteer receives job via WebSocket
5. Volunteer fetches Wasm from IPFS gateway (Boxo-powered)
6. Volunteer executes Wasm in browser sandbox
7. Volunteer returns result via WebSocket
8. Orchestrator stores result in blockstore
9. Developer retrieves result via GET /api/jobs/{id}
```

---

## 4. Project Structure

```
zerverless/
├── .github/
│   └── workflows/
│       └── ci.yml
├── cmd/
│   └── orchestrator/
│       └── main.go              # Application entry point
├── internal/
│   ├── api/
│   │   ├── routes.go            # HTTP API routes (chi)
│   │   ├── handlers.go          # Request handlers
│   │   └── middleware.go        # Auth, logging, etc.
│   ├── ws/
│   │   ├── server.go            # WebSocket server
│   │   ├── volunteer.go         # Volunteer connection handler
│   │   └── messages.go          # Message types
│   ├── job/
│   │   ├── job.go               # Job model
│   │   ├── queue.go             # Job queue implementation
│   │   └── scheduler.go         # Job assignment logic
│   ├── volunteer/
│   │   ├── volunteer.go         # Volunteer model
│   │   └── manager.go           # Connection tracking
│   ├── peer/
│   │   ├── peer.go              # Peer model
│   │   ├── manager.go           # libp2p peer management
│   │   └── protocol.go          # Custom protocol handlers
│   ├── ipfs/
│   │   ├── node.go              # Boxo IPFS node setup
│   │   ├── store.go             # Content storage helpers
│   │   └── gateway.go           # Gateway configuration
│   └── config/
│       └── config.go            # Configuration management
├── pkg/
│   └── protocol/
│       └── messages.go          # Shared protocol definitions
├── volunteer/
│   ├── index.html               # Volunteer web UI
│   ├── volunteer.js             # WebSocket client + Wasm executor
│   └── styles.css               # Styling
├── docker/
│   ├── Dockerfile               # Production multi-stage build
│   └── Dockerfile.dev           # Development with hot reload
├── scripts/
│   ├── dev.sh                   # Development helper
│   └── seed_jobs.go             # Seed test jobs
├── docker-compose.yml           # Base compose file
├── docker-compose.dev.yml       # Development overrides
├── go.mod                       # Go module definition
├── go.sum                       # Dependency checksums
├── .env.example                 # Example environment variables
├── .gitignore
├── Makefile                     # Common commands
└── README.md
```

---

## 5. Data Models

### 5.1 Job Model

```go
// internal/job/job.go

package job

import (
    "time"
    "github.com/google/uuid"
)

type Status string

const (
    StatusPending   Status = "pending"
    StatusAssigned  Status = "assigned"
    StatusRunning   Status = "running"
    StatusCompleted Status = "completed"
    StatusFailed    Status = "failed"
    StatusTimeout   Status = "timeout"
)

type Job struct {
    ID             string         `json:"id"`
    WasmCID        string         `json:"wasm_cid"`
    InputData      map[string]any `json:"input_data"`
    Status         Status         `json:"status"`
    Result         any            `json:"result,omitempty"`
    Error          string         `json:"error,omitempty"`
    CreatedAt      time.Time      `json:"created_at"`
    AssignedAt     *time.Time     `json:"assigned_at,omitempty"`
    CompletedAt    *time.Time     `json:"completed_at,omitempty"`
    AssignedTo     string         `json:"assigned_to,omitempty"`
    TimeoutSeconds int            `json:"timeout_seconds"`
    Retries        int            `json:"retries"`
    MaxRetries     int            `json:"max_retries"`
}

func New(wasmCID string, input map[string]any, timeout int) *Job {
    return &Job{
        ID:             uuid.NewString(),
        WasmCID:        wasmCID,
        InputData:      input,
        Status:         StatusPending,
        CreatedAt:      time.Now().UTC(),
        TimeoutSeconds: timeout,
        MaxRetries:     3,
    }
}

// Request/Response types
type CreateRequest struct {
    WasmCID        string         `json:"wasm_cid"`
    InputData      map[string]any `json:"input_data"`
    TimeoutSeconds int            `json:"timeout_seconds"`
}

type Response struct {
    ID          string     `json:"id"`
    Status      Status     `json:"status"`
    Result      any        `json:"result,omitempty"`
    Error       string     `json:"error,omitempty"`
    CreatedAt   time.Time  `json:"created_at"`
    CompletedAt *time.Time `json:"completed_at,omitempty"`
}
```

### 5.2 Volunteer Model

```go
// internal/volunteer/volunteer.go

package volunteer

import (
    "time"
    "github.com/google/uuid"
)

type Status string

const (
    StatusIdle         Status = "idle"
    StatusBusy         Status = "busy"
    StatusDisconnected Status = "disconnected"
)

type Capabilities struct {
    Wasm        bool `json:"wasm"`
    MaxMemoryMB int  `json:"max_memory_mb"`
}

type Volunteer struct {
    ID            string       `json:"id"`
    ConnectedAt   time.Time    `json:"connected_at"`
    LastHeartbeat time.Time    `json:"last_heartbeat"`
    Status        Status       `json:"status"`
    CurrentJobID  string       `json:"current_job_id,omitempty"`
    JobsCompleted int          `json:"jobs_completed"`
    JobsFailed    int          `json:"jobs_failed"`
    Capabilities  Capabilities `json:"capabilities"`
    UserAgent     string       `json:"user_agent,omitempty"`
}

func New() *Volunteer {
    now := time.Now().UTC()
    return &Volunteer{
        ID:            uuid.NewString(),
        ConnectedAt:   now,
        LastHeartbeat: now,
        Status:        StatusIdle,
        Capabilities:  Capabilities{Wasm: true, MaxMemoryMB: 128},
    }
}
```

### 5.3 Peer Model

```go
// internal/peer/peer.go

package peer

import (
    "time"
    "github.com/libp2p/go-libp2p/core/peer"
)

type Status string

const (
    StatusConnected    Status = "connected"
    StatusDisconnected Status = "disconnected"
    StatusConnecting   Status = "connecting"
)

type Peer struct {
    ID             peer.ID   `json:"id"`
    Addrs          []string  `json:"addrs"`
    ConnectedAt    time.Time `json:"connected_at"`
    LastSeen       time.Time `json:"last_seen"`
    Status         Status    `json:"status"`
    VolunteerCount int       `json:"volunteer_count"`
    Load           float64   `json:"load"`
}
```

---

## 6. API Contracts

All API contracts (HTTP, WebSocket, P2P) are documented in **[contracts.md](contracts.md)**.

### Quick Reference

#### HTTP Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Health check |
| GET | `/info` | Node info |
| GET | `/stats` | Statistics |
| POST | `/api/jobs` | Submit job |
| GET | `/api/jobs/{id}` | Get job |
| GET | `/api/jobs` | List jobs |
| DELETE | `/api/jobs/{id}` | Cancel job |
| GET | `/api/peers` | List peers |
| GET | `/api/volunteers` | List volunteers |

#### WebSocket

| Endpoint | Description |
|----------|-------------|
| `ws://host:port/ws/volunteer` | Volunteer connection |

#### P2P Protocols (libp2p)

| Protocol ID | Description |
|-------------|-------------|
| `/zerverless/job/1.0.0` | Job forwarding |
| `/zerverless/stats/1.0.0` | Stats sync |

See **[contracts.md](contracts.md)** for full request/response schemas and message formats.

---

## 7. Docker Development Setup

### 7.1 docker-compose.yml (Base)

```yaml
version: "3.8"

services:
  orchestrator-a:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: zerverless-orchestrator-a
    environment:
      - NODE_ID=node-a
      - HTTP_PORT=8000
      - LIBP2P_PORT=4001
      - BOOTSTRAP_PEERS=/ip4/orchestrator-b/tcp/4001/p2p/...
    ports:
      - "8000:8000"   # HTTP API
      - "4001:4001"   # libp2p
    volumes:
      - node_a_data:/data

  orchestrator-b:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: zerverless-orchestrator-b
    environment:
      - NODE_ID=node-b
      - HTTP_PORT=8000
      - LIBP2P_PORT=4001
      - BOOTSTRAP_PEERS=/ip4/orchestrator-a/tcp/4001/p2p/...
    ports:
      - "8001:8000"
      - "4002:4001"
    volumes:
      - node_b_data:/data

  volunteer-ui:
    image: nginx:alpine
    container_name: zerverless-volunteer-ui
    ports:
      - "3000:80"
    volumes:
      - ./volunteer:/usr/share/nginx/html:ro

volumes:
  node_a_data:
  node_b_data:
```

### 7.2 docker-compose.dev.yml (Development Overrides)

```yaml
version: "3.8"

services:
  orchestrator-a:
    build:
      context: .
      dockerfile: docker/Dockerfile.dev
    volumes:
      - .:/app:cached
      - go_mod_cache:/go/pkg/mod
    environment:
      - DEBUG=1
      - LOG_LEVEL=debug

  orchestrator-b:
    build:
      context: .
      dockerfile: docker/Dockerfile.dev
    volumes:
      - .:/app:cached
      - go_mod_cache:/go/pkg/mod
    environment:
      - DEBUG=1
      - LOG_LEVEL=debug

volumes:
  go_mod_cache:
```

### 7.3 docker/Dockerfile (Production)

```dockerfile
# Build stage
FROM golang:1.22-alpine AS builder

WORKDIR /app

# Install dependencies
COPY go.mod go.sum ./
RUN go mod download

# Copy source and build
COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -o /orchestrator ./cmd/orchestrator

# Runtime stage
FROM alpine:3.19

RUN apk add --no-cache ca-certificates

COPY --from=builder /orchestrator /orchestrator

EXPOSE 8000 4001

CMD ["/orchestrator"]
```

### 7.4 docker/Dockerfile.dev (Development)

```dockerfile
FROM golang:1.22-alpine

WORKDIR /app

# Install air for hot reload
RUN go install github.com/air-verse/air@latest

# Copy go.mod for dependency caching
COPY go.mod go.sum ./
RUN go mod download

EXPOSE 8000 4001

CMD ["air", "-c", ".air.toml"]
```

### 7.5 Makefile

```makefile
.PHONY: dev up down logs test lint build clean

# Development with hot reload
dev:
	docker compose -f docker-compose.yml -f docker-compose.dev.yml up

# Development with rebuild
dev-build:
	docker compose -f docker-compose.yml -f docker-compose.dev.yml up --build

# Production mode
up:
	docker compose up -d

# Stop all containers
down:
	docker compose -f docker-compose.yml -f docker-compose.dev.yml down

# View logs
logs:
	docker compose -f docker-compose.yml -f docker-compose.dev.yml logs -f

# Run tests
test:
	go test ./... -v -race -cover

# Run linter
lint:
	golangci-lint run

# Build binary
build:
	go build -o bin/orchestrator ./cmd/orchestrator

# Clean up
clean:
	docker compose -f docker-compose.yml -f docker-compose.dev.yml down -v --rmi local
	rm -rf bin/
```

---

## 8. Configuration

### 8.1 Configuration Schema

```go
// internal/config/config.go

package config

import (
    "os"
    "strconv"
    "strings"
)

type Config struct {
    // Node identity
    NodeID string
    
    // HTTP server
    HTTPPort int
    
    // libp2p
    Libp2pPort     int
    BootstrapPeers []string
    
    // IPFS/Boxo
    DataDir string
    
    // Job settings
    DefaultJobTimeout int
    MaxJobRetries     int
    JobQueueMaxSize   int
    
    // Volunteer settings
    VolunteerHeartbeatInterval int
    VolunteerTimeout           int
    
    // Debug
    Debug    bool
    LogLevel string
}

func Load() *Config {
    return &Config{
        NodeID:                     getEnv("NODE_ID", "node-default"),
        HTTPPort:                   getEnvInt("HTTP_PORT", 8000),
        Libp2pPort:                 getEnvInt("LIBP2P_PORT", 4001),
        BootstrapPeers:             getEnvList("BOOTSTRAP_PEERS"),
        DataDir:                    getEnv("DATA_DIR", "/data"),
        DefaultJobTimeout:          getEnvInt("DEFAULT_JOB_TIMEOUT", 30),
        MaxJobRetries:              getEnvInt("MAX_JOB_RETRIES", 3),
        JobQueueMaxSize:            getEnvInt("JOB_QUEUE_MAX_SIZE", 1000),
        VolunteerHeartbeatInterval: getEnvInt("VOLUNTEER_HEARTBEAT_INTERVAL", 30),
        VolunteerTimeout:           getEnvInt("VOLUNTEER_TIMEOUT", 60),
        Debug:                      getEnvBool("DEBUG", false),
        LogLevel:                   getEnv("LOG_LEVEL", "info"),
    }
}

func getEnv(key, fallback string) string {
    if v := os.Getenv(key); v != "" {
        return v
    }
    return fallback
}

func getEnvInt(key string, fallback int) int {
    if v := os.Getenv(key); v != "" {
        if i, err := strconv.Atoi(v); err == nil {
            return i
        }
    }
    return fallback
}

func getEnvBool(key string, fallback bool) bool {
    if v := os.Getenv(key); v != "" {
        return v == "true" || v == "1"
    }
    return fallback
}

func getEnvList(key string) []string {
    if v := os.Getenv(key); v != "" {
        return strings.Split(v, ",")
    }
    return nil
}
```

### 8.2 .env.example

```bash
# Node Configuration
NODE_ID=node-dev
DEBUG=true
LOG_LEVEL=debug

# HTTP Server
HTTP_PORT=8000

# libp2p
LIBP2P_PORT=4001
BOOTSTRAP_PEERS=/ip4/127.0.0.1/tcp/4002/p2p/12D3KooW...

# Storage
DATA_DIR=/data

# Job Settings
DEFAULT_JOB_TIMEOUT=30
MAX_JOB_RETRIES=3
JOB_QUEUE_MAX_SIZE=1000

# Volunteer Settings
VOLUNTEER_HEARTBEAT_INTERVAL=30
VOLUNTEER_TIMEOUT=60
```

---

## 9. Development Phases

### Phase 1: Hello Volunteers (Foundation)

**Goal:** WebSocket server accepts volunteer connections

**Tasks:**

- [ ] Initialize Go module with dependencies
- [ ] Create chi HTTP router skeleton
- [ ] Implement WebSocket endpoint `/ws/volunteer`
- [ ] Create VolunteerManager (connect, disconnect, track)
- [ ] Add `/health` and `/stats` endpoints
- [ ] Create basic volunteer HTML/JS client
- [ ] Docker Compose setup with hot reload
- [ ] Basic test setup

**Success Criteria:**

- Multiple browser tabs can connect as volunteers
- `/stats` shows correct volunteer count
- Disconnection handled gracefully

---

### Phase 2: Run Some Code (Job Execution)

**Goal:** Send jobs to volunteers, get results

**Tasks:**

- [ ] Create Job model and Queue
- [ ] Implement `POST /api/jobs` endpoint
- [ ] Implement `GET /api/jobs/{id}` endpoint
- [ ] Add job dispatch logic (queue → available volunteer)
- [ ] Handle results via WebSocket
- [ ] Add job timeout handling
- [ ] Update volunteer client to execute JavaScript (prototype only)

**Success Criteria:**

- Submit job via HTTP, receive result
- Jobs timeout if volunteer dies
- Multiple jobs queue correctly

---

### Phase 3: Wasm Sandbox (Security)

**Goal:** Execute Wasm instead of raw code

**Tasks:**

- [ ] Create sample Wasm module (TinyGo or Rust)
- [ ] Update volunteer client for Wasm execution
- [ ] Pass input/output through Wasm memory
- [ ] Add resource limits (memory, time)
- [ ] Handle Wasm compilation errors

**Success Criteria:**

- Volunteer executes Wasm modules
- Bad Wasm doesn't crash volunteer
- Memory limits enforced

---

### Phase 4: IPFS Storage (Boxo Integration)

**Goal:** Store Wasm and results using Boxo

**Tasks:**

- [ ] Initialize Boxo blockstore and blockservice
- [ ] Jobs reference Wasm by CID
- [ ] Upload Wasm via `POST /api/wasm`
- [ ] Configure Boxo gateway for volunteers
- [ ] Store results in blockstore (optional)

**Success Criteria:**

- Wasm stored in Boxo, referenced by CID
- Volunteers fetch from Boxo gateway
- Content persists across restarts

---

### Phase 5: P2P Network (libp2p)

**Goal:** Multiple orchestrators communicate via libp2p

**Tasks:**

- [ ] Initialize libp2p host
- [ ] Set up Kademlia DHT
- [ ] Create custom job forwarding protocol
- [ ] Share load/stats with peers
- [ ] Forward jobs to less-loaded peer
- [ ] Handle peer disconnection

**Success Criteria:**

- Two orchestrators discover each other via DHT
- Job submitted to A can execute on B's volunteer
- Peer failure handled gracefully
- New nodes join by knowing one bootstrap

---

### Phase 6: Production Hardening

**Goal:** Make it production-ready

**Tasks:**

- [ ] Add authentication for job submission
- [ ] Rate limiting
- [ ] Metrics/monitoring (Prometheus)
- [ ] Structured logging
- [ ] Graceful shutdown
- [ ] Health check improvements

---

### Phase 7: Native Volunteer Client (Future)

**Goal:** Desktop/CLI volunteer client

**Tasks:**

- [ ] CLI client using wazero
- [ ] Desktop client (optional)
- [ ] Mobile client (ambitious)

---

## 10. Testing Strategy

### 10.1 Test Structure

```
internal/
├── api/
│   └── routes_test.go
├── ws/
│   └── server_test.go
├── job/
│   ├── job_test.go
│   └── queue_test.go
├── volunteer/
│   └── manager_test.go
├── peer/
│   └── manager_test.go
└── integration_test.go
```

### 10.2 Test Examples

```go
// internal/job/queue_test.go

package job

import (
    "testing"
)

func TestQueue_Push(t *testing.T) {
    q := NewQueue(10)
    job := New("QmTest...", nil, 30)
    
    err := q.Push(job)
    if err != nil {
        t.Fatalf("unexpected error: %v", err)
    }
    
    if q.Len() != 1 {
        t.Errorf("expected len 1, got %d", q.Len())
    }
}

func TestQueue_Pop(t *testing.T) {
    q := NewQueue(10)
    job := New("QmTest...", nil, 30)
    q.Push(job)
    
    popped := q.Pop()
    if popped.ID != job.ID {
        t.Errorf("expected job %s, got %s", job.ID, popped.ID)
    }
}
```

```go
// internal/api/routes_test.go

package api

import (
    "net/http"
    "net/http/httptest"
    "testing"
)

func TestHealthEndpoint(t *testing.T) {
    r := NewRouter(nil)
    
    req := httptest.NewRequest("GET", "/health", nil)
    w := httptest.NewRecorder()
    
    r.ServeHTTP(w, req)
    
    if w.Code != http.StatusOK {
        t.Errorf("expected 200, got %d", w.Code)
    }
}
```

---

## 11. Future Considerations

### 11.1 Native Volunteer Client

Browser is Phase 1. Later:

- CLI client (wazero runtime)
- Desktop client (Wails or Tauri)
- Mobile client (ambitious)

### 11.2 Security Enhancements

- Volunteer reputation system
- Job result verification (redundant execution)
- Rate limiting
- Authentication for job submission

### 11.3 Governance

- Non-profit foundation
- Open collective for donations
- Transparent resource allocation

---

## Quick Start Commands

```bash
# Clone and setup
git clone <repo>
cd zerverless

# Start as orchestrator (default)
make dev

# Or build and run
make build
./bin/zerverless

# Run as worker (connect to orchestrator)
./bin/zerverless --worker ws://localhost:8000/ws/volunteer

# Run tests
make test

# Docker development
make docker-dev

# Stop everything
make docker-down
```

## CLI Usage

```
Zerverless - Distributed compute platform

Usage:
  zerverless [flags]

Modes:
  Orchestrator (default): Run as job coordinator
  Worker: Connect to orchestrator and execute jobs

Flags:
  --worker string   Run as worker connecting to orchestrator WebSocket URL

Examples:
  zerverless                                         # Run as orchestrator
  zerverless --worker ws://localhost:8000/ws/volunteer  # Run as worker
```

## URLs When Running

|Service|URL|
|---|---|
|Orchestrator A API|http://localhost:8000|
|Orchestrator B API|http://localhost:8001|
|Volunteer UI|http://localhost:3000|

---

_This specification is a living document. Update as the project evolves._
